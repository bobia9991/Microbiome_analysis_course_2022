---
title: " Microbial Data Analysis Course Part 2"
output: html_document 
date: "15-03-2022"
---

This is the schedule for the practical session:

- Differential abundance analysis: 40 minutes
- Break: 10 minutes
- Break: 10 minutes
- Machine learning modelling with SIAMCAT: 50 minutes
- Conclusions: 10 minutes


## Loading packages and data in R

We first load the packages that we will employ during the tutorial

```{r, message=FALSE}
library(knitr)
library(tidyverse)
# library(reshape2)
# library(dplyr)
# library(plyr)
# library(ggrepel)
library(ggplot2)
# library(ggpubr)
library(pROC)
# library(car)
# library(vegan)
library(SIAMCAT)

set.seed(540832)
```

Next, we read the data tables that contain the count matrix and samples' metadata. 
```{r, message=FALSE}
# set the working directory
setwd("~/Documents/SAEZ/teaching/Microbiome_analysis_course_2022/")
load("data/mobi.Rdata")
folder.results= paste0(getwd(), "/results/")
```

################################################################################
# Differential Abundance Analysis
################################################################################

## Normalization

There are multiple factors that can result in libraries of different sizes. 
Those include experimental variations, batch effects or simply, different sequencing depths. 
We assume that, if it were not for these variations, all samples should have a similar 
range and distribution of abundance. Therefore, after data filtering, a normalization step 
is necessary to ensure that species abundance can be compared between samples and experimental 
conditions. Below, we use the relative abundance. There are other normalisation approaches described 
in [Pereira et al. 2018](https://bmcgenomics.biomedcentral.com/articles/10.1186/s12864-018-4637-6).

```{r}
# filter low abundant taxa
motu.abs.fil <- motu.abs[rowSums(motu.abs >= 10^-5) >= 2, ]
dim(motu.abs.fil)

# apply normalization function
motu.abs.rel <- prop.table(as.matrix(motu.abs), 2)
motu.abs.fil.rel <- prop.table(as.matrix(motu.abs.fil), 2)
```

And have a look to how the normalized values look like:

```{r}
head(motu.abs.fil.rel)
```


## Differential Abundance Analysis with Wilcoxin Test

Next, we can analyze the differences between the microbiome profiles of both groups. To do so, we use `wilcoxin test` which is a statistical test where all species in the count matrix are compared between the sample groups of interest.  `wilcoxin test` is not the only option to perform Differential Abundance Analysis. Common alternatives include [`edgeR`](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2796818/) and [`DESeq2`](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-014-0550-8).



```{r}
featTable=motu.abs.fil.rel
metaTable=meta
metaTable$ID = rownames(metaTable)

##############################################################################
p.cal <- tribble(~ID, ~pval, ~adj.pval, ~log10, ~aucs.mat, ~fc, ~sig )
  
for (rowname in row.names(featTable)) {
    # define matrix to compare
    x <- as.numeric(featTable[rowname, metaTable %>% filter(status=='PC') %>% pull(ID)])
    y <- as.numeric(featTable[rowname, metaTable %>% filter(status=='CTR') %>% pull(ID)])

    # Fold change
    q.p <- quantile(log10(x+1e-05), probs=seq(.1, .9, .05))
    q.n <- quantile(log10(y+1e-05), probs=seq(.1, .9, .05))
   
    # create matrix
    p.cal=add_row(p.cal, 
                  ID = rowname,
                  pval = wilcox.test(x, y, exact=FALSE)$p.value,
                  adj.pval = p.adjust(pval, method = "fdr", 2),
                  log10 = -log10((adj.pval) ),
                  aucs.mat = roc(controls=y, cases=x, direction='<', ci=TRUE, auc=TRUE)$ci[2], 
                  fc = sum(q.p - q.n)/length(q.p),
                  sig = ifelse(adj.pval < 0.05, "p.adj < 0.05", "not sig"))
}
  
# save file
write.table(p.cal, file=paste0(folder.results, 'wilcox.results.tsv'), 
            sep='\t', row.names=TRUE, col.names=TRUE)
```
And look at the distribution of the adjusted P values:

```{r}
ggplot2::ggplot(p.cal, aes(x = adj.P.Val)) +
  ggplot2::geom_histogram()
```

**NOTE:** Do you remember how the P-value distribution should look like? If not, please see [here](http://varianceexplained.org/statistics/interpreting-pvalue-histogram/).

Our P-value histogram clearly shows an anti-conservative distribution. We can also visualize the gene expression changes using one of the most common plots to explore DE results, the **volcano plot**:
```{r}


#  volcano plots
ggplot2::ggplot(de_table, aes(x = logFC,-log10(adj.P.Val), color = status)) +
  ggplot2::geom_point() +
  ggplot2::geom_vline(xintercept = log2(c(0.25, 0.5, 2, 4)), lty = 2) +
  ggplot2::geom_hline(yintercept = -log10(c(0.05, 0.01, 0.001, 0.0001)), lty = 2) +
  ggplot2::scale_color_manual(values = c(
    "Up" = "red",
    "Down" = "blue",
    "Other" = "black"
  ))


# Volcano plot significant features
plot.volcano <- function(p.adj.df, plot.name){
  p <- ggplot(p.adj.df, aes(x = sc.fc, y = log10p)) +
    geom_point(aes(size=rel, color = significant), alpha=0.5) +
    scale_color_manual(values = c("black","red")) +
    theme_bw(base_size = 20) +
    geom_hline(yintercept=-log10(0.05))+
    geom_text_repel(data = subset(p.adj.df, adj < 0.05),
                    aes(label = species),
                    size = 3,
                    box.padding = unit(0.2, "lines"),
                    point.padding = unit(0.2, "lines")) +
    ggtitle("Differentially abundant species") +
    xlab("Generalized fold change") + 
    ylab("Log10 adjusted p-value") +
    theme_classic()
  
  print(p)
  # save plot
  ggsave(p, filename=paste0(PARAM$folder.results, plot.name, "wilcox.volcano.pdf"), 
         width = 5.5, height=6)
```


A volcano plot enables us to quickly visualize the magnitude (logFC) and significance (-log10(pvalue)) of DE changes. Each point represent a gene, and its color indicates whether they surpass or not a cutoff of an absolute logFC > `r fc_cutoff` and an adjusted P value < `r p_cutoff`. 

**QUESTION**: What do the horizontal and vertical dashed lines mean in this plot? Take a look at the code and think about their meaning. 

**QUESTION**: Try to modify the `fc_cutoff` and and `p_cutoff` variables in this chunk. What happens? What cutoff values should we use? 

# Functional analysis

Thanks to the DEA, we know which species are different between the two cell lines, with measurements that indicate us the magnitude and the significance of the changes. But now we face one of the most prominent bottlenecks in the analysis of omics data: The extraction of biological insights that we can further interpret and link to a particular phenotype. 
```{r}
meta.train <- meta
feat.train <- feat.all
  
siamcat <- siamcat(feat=feat.train, meta=meta.train,
                    label = 'status', case='PC')
siamcat <- filter.features(siamcat, filter.method = 'abundance', 
                             cutoff=0.001, verbose=3)
siamcat <- normalize.features(siamcat, norm.method = norm.method,
                                norm.param = n.p, feature.type = 'filtered',
                                verbose=3)
siamcat <- create.data.split(siamcat, num.folds = num.folds,
                               num.resample = num.resample)
siamcat <- train.model(siamcat,
                         method = model
                        )
siamcat <- make.predictions(siamcat)
siamcat <- evaluate.predictions(siamcat)
models[[model]] <- siamcat
save(siamcat, file=paste0(PARAM$folder.R, 'nonfiltered.RData'))


siamcat <- siamcat(feat=featTable, meta=metaTable, label="subject_disease_status", case=case)
  
  # filter based on abundance 
  siamcat <- filter.features(siamcat, filter.method = 'abundance', 
                             cutoff=0.001, verbose=3)
  check.confounders(siamcat, fn.plot = paste0(PARAM$folder.results, 
                                              fileName, 'confounders.pdf'),
                    meta.in=metatest, verbose = 3)
  
  # normalize with log.clr
  siamcat <- normalize.features(siamcat, norm.method = "log.clr", feature.type = 'filtered',
                                norm.param = list(log.n0=1e-05, sd.min.q=1))
  
  # compute associations 
  siamcat <- check.associations(siamcat, feature.type = 'normalized', 
                                detect.lim = 10^-5, plot.type = "quantile.box",
                                fn.plot = paste0(PARAM$folder.results, 
                                                 Sys.Date(), '.', fileName,'assoc.plot.pdf'))
  
  # train model
  siamcat <- create.data.split(siamcat, num.folds =10, num.resample = 10)  
  siamcat <- train.model(siamcat, method = "lasso_ll", verbose = 2)
  siamcat <- make.predictions(siamcat)
  siamcat <- evaluate.predictions(siamcat)    
  print(siamcat@eval_data$auroc)
  # evaluation plot
  model.evaluation.plot(siamcat, fn.plot = paste0(PARAM$folder.results, Sys.Date(), '.',
                                                  fileName, 'eval.plot.pdf'))
  # interpretation plot
  model.interpretation.plot(siamcat, fn.plot = paste0(PARAM$folder.results, 
                                                      Sys.Date(), '.', fileName,'interpret.plot.pdf'),
                            consens.thres = 0.5,
                            detect.lim = 1e-05,
                            heatmap.type = 'zscore')
  
  # save siamcat object
  save(siamcat, file = paste0(PARAM$folder.results, fileName, 'siamcat.Rdata'))
```

```{r}
# add confounders to model
add.meta <- function(x, n){
  x <- add.meta.pred(x, pred.names = n, verbose=3)
  x <- train.model(x, method='lasso_ll', verbose=2, perform.fs = TRUE,
                   param.fs = list(thres.fs=50, method.fs='gFC', 
                                   direction='positive'))
  x <- make.predictions(x)
  x <- evaluate.predictions(x)
  return(x)
}
# combine with naive model
siamcat.jau <- add.meta(siamcat.pc, 'jaundice')
```

